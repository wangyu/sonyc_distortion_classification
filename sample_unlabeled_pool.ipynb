{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modAL.models import ActiveLearner\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample unlabeled pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = h5py.File('/scratch/yw3004/sonyc/sonyc_distortion_classification/_old_features.h5', 'r')\n",
    "d_features = list(features.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype([('path', 'S96'), ('identifier', 'S32'), ('features_z', 'u1', (10, 128))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_features.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2556319,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = h5py.File('/scratch/yw3004/sonyc/sonyc_distortion_classification/clusters_frames.hdf5', 'r')\n",
    "d_frames = list(frames.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype([('assignment', '<u4'), ('frame', 'u1'), ('sensor_id', 'S32'), ('timestamp', '<f8')])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_frames.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25563190,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_frames['frame'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_clusters = [9,11,24,25,40,49,52,60,61,75,78,94,95,106,107,124,129]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pool(num_samples):\n",
    "    positive_samples = []\n",
    "    negative_samples = []\n",
    "    \n",
    "    #generate random index sequence\n",
    "    idx = list(range(0,len(d_frames)))\n",
    "    random.shuffle(idx)\n",
    "    \n",
    "    for ind in idx:\n",
    "        #if  got enough samples, stop the loop\n",
    "        if len(negative_samples) ==  len(positive_samples) == num_samples//2:\n",
    "            break\n",
    "            \n",
    "        #if assigned to negative clusters, add to negative samples\n",
    "        elif d_frames[ind]['assignment'] not in positive_clusters and len(negative_samples) < num_samples//2:\n",
    "            identifier = (d_frames[ind]['sensor_id'].decode('UTF-8')+'_'+str(d_frames[ind]['timestamp'])).encode('UTF-8')\n",
    "            negative_samples.append((identifier, int(d_frames[ind]['frame'])))\n",
    "       \n",
    "        #if assigned to positive clusters, add to positive samples\n",
    "        elif d_frames[ind]['assignment'] in positive_clusters and len(positive_samples) < num_samples//2:\n",
    "            identifier = (d_frames[ind]['sensor_id'].decode('UTF-8')+'_'+str(d_frames[ind]['timestamp'])).encode('UTF-8')\n",
    "            positive_samples.append((identifier, int(d_frames[ind]['frame'])))\n",
    "\n",
    "    #list of identifier(sensor id, timestamp and frame) of samples in the pool\n",
    "    id_pool = positive_samples + negative_samples\n",
    "        \n",
    "    X_pool = np.empty([num_samples, 128])\n",
    "    #get VGG features for each index\n",
    "    notfound_inds = []\n",
    "    notfound_ids = []\n",
    "    for i in range(num_samples):\n",
    "        identifier = id_pool[i][0]\n",
    "        frame = id_pool[i][1]\n",
    "        ind = np.where(d_features['identifier'] == identifier)\n",
    "        try:\n",
    "            X_pool[i] = d_features[ind[0][0]]['features_z'][frame,:]\n",
    "        except IndexError:\n",
    "            notfound_inds.append(i)\n",
    "            notfound_ids.append(identifier)\n",
    "            \n",
    "    X_pool = np.delete(X_pool, notfound_inds, 0)    \n",
    "            \n",
    "    return id_pool, X_pool, notfound_ids, notfound_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_pool, X_pool, notfound_ids, notfound_inds = build_pool(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(998, 128)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pool.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'74da385c687d_1481419829.11', b'74da385c683d_1483808189.4']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notfound_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(X_pool, open(\"X_pool.pickle\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(id_pool, open(\"id_pool.pickle\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load initial training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_xy = pickle.load( open( \"positive_xy.pickle\", \"rb\" ) )\n",
    "negative_xy = pickle.load( open( \"negative_xy.pickle\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170, 129)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_xy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Active learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_training = np.array([[1,2],[1,1],[-1,-2],[-3,-1]])\n",
    "y_training = np.array([1,1,0,0])\n",
    "\n",
    "X_pool = np.array([[-1,1],[-5,-3],[3,-2],[0,0]])\n",
    "\n",
    "# initializing the learner\n",
    "learner = ActiveLearner(\n",
    "    estimator=RandomForestClassifier(),\n",
    "    X_training=X_training, y_training=y_training)\n",
    "\n",
    "# query for labels\n",
    "query_idx, query_inst = learner.query(X_pool)\n",
    "\n",
    "# ...obtaining new labels from the Oracle...\n",
    "\n",
    "# supply label for queried instance\n",
    "# y_new = np.array([0])\n",
    "learner.teach(X_pool[query_idx], y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update training set and pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_train_and_pool(X_training, y_training, X_pool, queried_samples, query_idx, new_labels):\n",
    "    \n",
    "    X_training = np.vstack(X_training, X_pool(query_idx))\n",
    "    y_training = np.append(y_training, new_labels)\n",
    "    queried_samples = np.append(queried_samples, X_pool[query_idx])\n",
    "    X_pool = np.delete(X_pool, (query_idx), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrain the model and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrain the model with new training set\n",
    "train(X_training, y_training)\n",
    "w = RandomForestClassifier.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate model performance on test set\n",
    "mean_acc = RandomForestClassifier(X_val, y_val, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "active_learning",
   "language": "python",
   "name": "active_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
